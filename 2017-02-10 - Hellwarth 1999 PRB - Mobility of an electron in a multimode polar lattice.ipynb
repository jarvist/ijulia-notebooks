{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hellwarth 1999 PRB - Part IV; T-dep of the Feynman variation parameter\n",
    "# A Friday afternoon of hacking to try and implement the T-dep electron-phonon coupling from the above PRB\n",
    "# Which was unusually succesful! And more or less reproduced Table III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 0.5.0\n",
      "Commit 3c9d753 (2016-09-19 18:14 UTC)\n",
      "Platform Info:\n",
      "  System: Darwin (x86_64-apple-darwin13.4.0)\n",
      "  CPU: Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz\n",
      "  WORD_SIZE: 64\n",
      "  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Haswell)\n",
      "  LAPACK: libopenblas64_\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-3.7.1 (ORCJIT, broadwell)\n"
     ]
    }
   ],
   "source": [
    "# Just in case anyone is following this from the far future; we are using:\n",
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-dimensional numerical integration in Julia using adaptive Gauss-Kronrod quadrature\n",
    "using QuadGK\n",
    "\n",
    "# Equation numbers follow above Hellwarth 1999 PRB\n",
    "# 62b\n",
    "A(v,w,β)=3/β*( log(v/w) - 1/2*log(2*π*β) - log(sinh(v*β/2)/sinh(w*β/2)))\n",
    "\n",
    "# 62d\n",
    "Y(x,v,β)=1/(1-exp(-v*β))*(1+exp(-v*β)-exp(-v*x)-exp(v*(x-β)))\n",
    "# 62c integrand\n",
    "f(x,v,w,β)=(exp(β-x)+exp(x))/(w^2*x*(1-x/β)+Y(x,v,β)*(v^2-w^2)/v)^(1/2)\n",
    "# 62c\n",
    "B(v,w,β,α) = α*v/(sqrt(π)*(exp(β)-1)) * quadgk(x->f(x,v,w,β),0,β/2)[1]\n",
    "#62e\n",
    "C(v,w,β)=3/4*(v^2-w^2)/v * (coth(v*β/2)-2/(v*β))\n",
    "\n",
    "F(v,w,β,α)=-(A(v,w,β)+B(v,w,β,α)+C(v,w,β)) #(62a)\n",
    "\n",
    "# Can now evaluate, e.g.\n",
    "# F(v,w,β,α)=F(7.2,6.5,1.0,1.0)\n",
    "# BUT - this is just the objective function! Not the optimised parameters.\n",
    "# Also there's a scary numeric integration (quadgk) buried within..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tα=1\t\tα=2\t\tα=3\t\tα=4\t\tα=5\t\t\n",
      "β: 1.0  \t||0.948149\t-0.860517\t-2.669184\t-4.477850\t-6.286517\t\n",
      "β: 1.25  \t||0.837826\t-0.797573\t-2.432973\t-4.068372\t-5.703771\t\n",
      "β: 1.5  \t||0.731167\t-0.781009\t-2.293184\t-3.805360\t-5.317535\t\n",
      "β: 1.75  \t||0.634483\t-0.786028\t-2.206538\t-3.627049\t-5.047560\t\n",
      "β: 2.0  \t||0.548050\t-0.802169\t-2.152387\t-3.502605\t-4.852824\t\n",
      "β: 2.25  \t||0.470735\t-0.824402\t-2.119538\t-3.414675\t-4.709811\t\n",
      "β: 2.5  \t||0.401226\t-0.850049\t-2.101324\t-3.352599\t-4.603874\t\n",
      "β: 2.75  \t||0.338349\t-0.877564\t-2.093476\t-3.309388\t-4.525300\t\n",
      "β: 3.0  \t||0.281128\t-0.905989\t-2.093106\t-3.280223\t-4.467340\t\n"
     ]
    }
   ],
   "source": [
    "# Print out F(alpha,beta) for a specific v,w; as a test\n",
    "@printf(\"\\t\\t\")\n",
    "for α in 1:5\n",
    "    @printf(\"α=%d\\t\\t\",α)\n",
    "end\n",
    "@printf(\"\\n\")\n",
    "\n",
    "for β in 1:0.25:3.0\n",
    "    v=w=4\n",
    "    print(\"β: $β  \\t||\")\n",
    "    for α in 1:5\n",
    "        @printf(\"%f\\t\",F(v,w,β,α))\n",
    "    end\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.000000 0.991013\n",
      "6.100000 0.980559\n",
      "6.200000 0.971051\n",
      "6.300000 0.962484\n",
      "6.400000 0.954852\n",
      "6.500000 0.948149\n",
      "6.600000 0.942368\n",
      "6.700000 0.937501\n",
      "6.800000 0.933540\n",
      "6.900000 0.930475\n",
      "7.000000 0.928297\n",
      "7.100000 0.926997\n",
      "7.200000 0.926565\n",
      "7.300000 0.926990\n",
      "7.400000 0.928261\n",
      "7.500000 0.930368\n",
      "7.600000 0.933300\n",
      "7.700000 0.937045\n",
      "7.800000 0.941592\n",
      "7.900000 0.946930\n",
      "8.000000 0.953047\n",
      "\n",
      "6.000000 0.936794\n",
      "6.100000 0.933154\n",
      "6.200000 0.930295\n",
      "6.300000 0.928232\n",
      "6.400000 0.926983\n",
      "6.500000 0.926565\n",
      "6.600000 0.926993\n",
      "6.700000 0.928281\n",
      "6.800000 0.930446\n",
      "6.900000 0.933502\n",
      "7.000000 0.937462\n"
     ]
    }
   ],
   "source": [
    "# OK - very primitive!\n",
    "# But these are 1D traces along the solution for Alpha=Beta=1 in Helwarth PRB TABLE III,\n",
    "# this was used to correct a transcription error in the above typed-in equations\n",
    "# It was also good to see what F(v,w) looked like as a function of v and w near an optimal solution\n",
    "\n",
    "v=7.20\n",
    "w=6.5\n",
    "α=1.0\n",
    "β=1.0\n",
    "\n",
    "for v=6:0.1:8\n",
    "    @printf(\"%f %f\\n\",v,F(v,w,β,α))\n",
    "end\n",
    "\n",
    "@printf(\"\\n\")\n",
    "v=7.20\n",
    "for w=6:0.1:7\n",
    "    @printf(\"%f %f\\n\",w,F(v,w,β,α))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Angle for the ringside seats, when the fall, don't blame me, Bring on the Major Leagues\n",
    "using Optim\n",
    "# Julia package stuffed full of magic, does auto-differentation & etc. etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9265650282717047"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fopt(x) = F(x[1],x[2],1,1)\n",
    "\n",
    "Fopt([7.2,6.5])\n",
    "# OK! It looks like I can bury the alpha, beta parameters (which we don't optimise), by wrapping our function in a function definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: L-BFGS\n",
       " * Starting Point: [7.2,6.5]\n",
       " * Minimizer: [7.200120820337425,6.4998864063978345]\n",
       " * Minimum: 9.265650e-01\n",
       " * Iterations: 5\n",
       " * Convergence: true\n",
       "   * |x - x'| < 1.0e-32: false\n",
       "   * |f(x) - f(x')| / |f(x)| < 1.0e-32: true\n",
       "   * |g(x)| < 1.0e-08: false\n",
       "   * Reached Maximum Number of Iterations: false\n",
       " * Objective Function Calls: 20\n",
       " * Gradient Calls: 20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial=[7.2,6.5]\n",
    "\n",
    "optimize(Fopt,  initial, LBFGS())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: BFGS\n",
       " * Starting Point: [7.2,6.5]\n",
       " * Minimizer: [7.2029649846871795,6.502749233940956]\n",
       " * Minimum: 9.265650e-01\n",
       " * Iterations: 3\n",
       " * Convergence: true\n",
       "   * |x - x'| < 1.0e-32: false\n",
       "   * |f(x) - f(x')| / |f(x)| < 1.0e-32: true\n",
       "   * |g(x)| < 1.0e-08: true\n",
       "   * Reached Maximum Number of Iterations: false\n",
       " * Objective Function Calls: 19\n",
       " * Gradient Calls: 19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize(Fopt, initial, BFGS(), Optim.Options(autodiff=true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: BFGS\n",
       " * Starting Point: [7.2,6.5]\n",
       " * Minimizer: [7.2029649846871795,6.502749233940956]\n",
       " * Minimum: 9.265650e-01\n",
       " * Iterations: 3\n",
       " * Convergence: true\n",
       "   * |x - x'| < 1.0e-32: false\n",
       "   * |f(x) - f(x')| / |f(x)| < 1.0e-32: true\n",
       "   * |g(x)| < 1.0e-08: true\n",
       "   * Reached Maximum Number of Iterations: false\n",
       " * Objective Function Calls: 19\n",
       " * Gradient Calls: 19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize(Fopt, initial, BFGS(), Optim.Options(autodiff=true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tα=1\t\tα=2\t\tα=3\t\tα=4\t\tα=5\t\t\n",
      "β: 1.0  \t||7.20 6.50\t7.69 6.20\t8.26 5.87\t8.95 5.51\t9.78 5.13\t\n",
      "β: 1.25  \t||5.94 5.31\t6.38 5.03\t6.91 4.73\t7.57 4.41\t8.39 4.05\t\n",
      "β: 1.5  \t||5.11 4.54\t5.52 4.29\t6.02 4.00\t6.66 3.70\t7.48 3.37\t\n",
      "β: 1.75  \t||4.54 4.01\t4.91 3.76\t5.40 3.51\t6.02 3.22\t6.83 2.92\t\n",
      "β: 2.0  \t||4.12 3.63\t4.48 3.40\t4.94 3.16\t"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "DomainError:",
     "output_type": "error",
     "traceback": [
      "DomainError:",
      "",
      " in nan_dom_err at ./math.jl:196 [inlined]",
      " in log(::Float64) at ./math.jl:202",
      " in A(::Float64, ::Float64, ::Float64) at ./In[3]:5",
      " in F(::Float64, ::Float64, ::Float64, ::Int64) at ./In[3]:16",
      " in (::#myf#3)(::Array{Float64,1}) at ./In[11]:12",
      " in alphatry(::Float64, ::Optim.DifferentiableFunction, ::Array{Float64,1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Array{Float64,1}, ::LineSearches.LineSearchResults{Float64}, ::Float64, ::Float64, ::Float64, ::Int64, ::Float64, ::Bool) at /Users/jarvist/.julia/v0.5/LineSearches/src/api.jl:26",
      " in update_state!(::Optim.DifferentiableFunction, ::Optim.ConjugateGradientState{Float64}, ::Optim.ConjugateGradient{Void,Optim.##29#31,LineSearches.#hagerzhang!}) at /Users/jarvist/.julia/v0.5/Optim/src/cg.jl:161",
      " in optimize(::Optim.DifferentiableFunction, ::Array{Float64,1}, ::Optim.ConjugateGradient{Void,Optim.##29#31,LineSearches.#hagerzhang!}, ::Optim.Options{Void}) at /Users/jarvist/.julia/v0.5/Optim/src/optimize.jl:200",
      " in optimize(::#myf#3, ::Array{Float64,1}, ::Optim.ConjugateGradient{Void,Optim.##29#31,LineSearches.#hagerzhang!}, ::Optim.Options{Void}) at /Users/jarvist/.julia/v0.5/Optim/src/optimize.jl:121",
      " in macro expansion; at ./In[11]:13 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "# Right! The above looks like this might actually just work...\n",
    "\n",
    "@printf(\"\\t\\t\")\n",
    "for α in 1:5\n",
    "    @printf(\"α=%d\\t\\t\",α)\n",
    "end\n",
    "@printf(\"\\n\")\n",
    "\n",
    "for β in 1:0.25:3.0\n",
    "    print(\"β: $β  \\t||\")\n",
    "    for α in 1:5\n",
    "        myf(x) = F(x[1],x[2],β,α)\n",
    "        solution=Optim.minimizer(optimize(myf, initial,ConjugateGradient(), Optim.Options(autodiff=true)))\n",
    "        \n",
    "        #print(solution,\"\\t\")\n",
    "        @printf(\"%.2f %.2f\\t\",solution[1],solution[2])\n",
    "    end\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tα=1\t\tα=2\t\tα=3\t\tα=4\t\tα=5\t\t\n",
      "β: 1.0  \t||7."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: could not attach metadata for @simd loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 6.50\t7.60 6.11\t8.28 5.89\t8.95 5.52\t9.77 5.12\t\n",
      "β: 1.25  \t||5.88 5.26\t6.40 5.05\t6.92 4.74\t7.57 4.41\t8.39 4.06\t\n",
      "β: 1.5  \t||5.08 4.51\t5.52 4.28\t6.01 4.00\t6.65 3.70\t7.48 3.38\t\n",
      "β: 1.75  \t||4.58 4.05\t4.93 3.78\t5.39 3.50\t6.02 3.23\t6.84 2.92\t\n",
      "β: 2.0  \t||4.14 3.65\t4.49 3.41\t4.94 3.16\t5.54 2.88\t6.37 2.60\t\n",
      "β: 2.25  \t||3.80 3.33\t4.17 3.16\t4.58 2.89\t5.18 2.64\t6.00 2.37\t\n",
      "β: 2.5  \t||3.58 3.14\t3.90 2.93\t4.32 2.70\t4.90 2.45\t5.71 2.20\t\n",
      "β: 2.75  \t||3.39 2.97\t3.69 2.77\t4.10 2.55\t4.67 2.31\t5.48 2.07\t\n",
      "β: 3.0  \t||3.25 2.85\t3.53 2.65\t3.93 2.43\t4.48 2.21\t5.28 1.97\t\n"
     ]
    }
   ],
   "source": [
    "# After a bit of fiddling, I figured out how to add bounds, to stop that 'DomainError', \n",
    "# which occurs where the you are evaluating log(-ve Real), i.e. w<0.0 or v<0.0\n",
    "\n",
    "initial=[7.2,6.5]\n",
    "\n",
    "lower=[0.0,0.0]\n",
    "upper=[10.0,10.0]\n",
    "\n",
    "@printf(\"\\t\\t\")\n",
    "for α in 1:5\n",
    "    @printf(\"α=%d\\t\\t\",α)\n",
    "end\n",
    "@printf(\"\\n\")\n",
    "\n",
    "for β in 1:0.25:3.0\n",
    "    print(\"β: $β  \\t||\")\n",
    "    for α in 1:5\n",
    "        myf(x) = F(x[1],x[2],β,α)\n",
    "        solution=optimize(DifferentiableFunction(myf), initial, lower, upper, Fminbox(); optimizer = ConjugateGradient, optimizer_o=Optim.Options(autodiff=true))\n",
    "        minimum=Optim.minimizer(solution)\n",
    "                \n",
    "        #print(solution,\"\\t\")\n",
    "        @printf(\"%.2f %.2f\\t\",minimum[1],minimum[2])\n",
    "    end\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t##### NOW TRIALING: Optim.BFGS{L<:Function,H<:Function} #####\n",
      "\n",
      "\t\tα=1\t\tα=2\t\tα=3\t\tα=4\t\tα=5\t\t\n",
      "β: 1.0  \t||7.15 6.45\t7.69 6.20\t8.17 5.78\t8.94 5.50\t9.77 5.12\t\n",
      "β: 1.25  \t||5.93 5.30\t6.38 5.03\t6.90 4.73\t7.58 4.42\t8.38 4.04\t\n",
      "β: 1.5  \t||5.12 4.55\t5.55 4.32\t6.02 4.00\t6.67 3.72\t7.48 3.37\t\n",
      "β: 1.75  \t||4.55 4.02\t4.94 3.79\t5.40 3.51\t6.02 3.22\t6.84 2.92\t\n",
      "β: 2.0  \t||4.16 3.66\t4.48 3.40\t4.95 3.17\t5.54 2.88\t6.36 2.60\t\n",
      "β: 2.25  \t||3.83 3.37\t4.16 3.14\t4.60 2.90\t5.17 2.63\t6.00 2.37\t\n",
      "β: 2.5  \t||3.60 3.16\t3.89 2.93\t4.32 2.70\t4.90 2.45\t5.71 2.20\t\n",
      "β: 2.75  \t||3.38 2.96\t3.68 2.75\t4.11 2.56\t4.67 2.31\t5.48 2.07\t\n",
      "β: 3.0  \t||3.26 2.86\t3.53 2.64\t3.93 2.43\t4.48 2.21\t5.29 1.97\t\n",
      "\n",
      "\t\t##### NOW TRIALING: Optim.LBFGS{T,L<:Function,Tprep<:Union{Function,Void}} #####\n",
      "\n",
      "\t\tα=1\t\tα=2\t\tα=3\t\tα=4\t\tα=5\t\t\n",
      "β: 1.0  \t||7.21 6.51\t7.71 6.23\t8.21 5.82\t8.95 5.52\t9.79 5.13\t\n",
      "β: 1.25  \t||5.95 5.32\t6.36 5.01\t6.90 4.72\t7.55 4.39\t8.39 4.05\t\n",
      "β: 1.5  \t||5.13 4.56\t5.53 4.29\t6.02 4.00\t6.64 3.69\t7.48 3.38\t\n",
      "β: 1.75  \t||4.53 4.01\t4.93 3.79\t5.39 3.50\t6.01 3.22\t6.84 2.92\t\n",
      "β: 2.0  \t||4.15 3.66\t4.49 3.41\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mWARNING: Linesearch failed, using alpha = 2.686099948427937e-11 and exiting optimization.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.93 3.15\t5.54 2.89\t6.36 2.61\t\n",
      "β: 2.25  \t||3.83 3.36\t4.14 3.13\t4.58 2.89\t5.18 2.64\t6.00 2.37\t\n",
      "β: 2.5  \t||3.57 3.13\t3.90 2.93\t4.32 2.70\t4.90 2.45\t5.71 2.20\t\n",
      "β: 2.75  \t||3.39 2.97\t3.69 2.77\t4.10 2.55\t4.67 2.31\t5.48 2.07\t\n",
      "β: 3.0  \t||3.22 2.82\t3.54 2.65\t3.93 2.44\t4.49 2.21\t5.29 1.97\t\n",
      "\n",
      "\t\t##### NOW TRIALING: Optim.ConjugateGradient{T,Tprep<:Union{Function,Void},L<:Function} #####\n",
      "\n",
      "\t\tα=1\t\tα=2\t\tα=3\t\tα=4\t\tα=5\t\t\n",
      "β: 1.0  \t||7.19 6.49\t7.67 6.18\t8.25 5.86\t8.96 5.53\t9.79 5.13\t\n",
      "β: 1.25  \t||5.91 5.28\t6.35 5.01\t6.89 4.72\t7.56 4.40\t8.39 4.05\t\n",
      "β: 1.5  \t||5.11 4.54\t5.51 4.28\t6.02 4.00\t6.66 3.70\t7.48 3.37\t\n",
      "β: 1.75  \t||4.53 4.00\t4.93 3.78\t5.39 3.51\t6.01 3.22\t6.84 2.92\t\n",
      "β: 2.0  \t||4.11 3.61\t4.49 3.41\t4.94 3.15\t5.54 2.88\t6.36 2.60\t\n",
      "β: 2.25  \t||3.81 3.35\t4.16 3.14\t4.60 2.90\t5.18 2.64\t6.00 2.37\t\n",
      "β: 2.5  \t||3.58 3.14\t3.89 2.92\t4.32 2.71\t4.89 2.45\t5.71 2.20\t\n",
      "β: 2.75  \t||3.37 2.96\t3.70 2.78\t4.11 2.56\t4.67 2.31\t5.48 2.07\t\n",
      "β: 3.0  \t||3.27 2.87\t3.53 2.65\t3.93 2.44\t4.49 2.21\t5.28 1.97\t\n"
     ]
    }
   ],
   "source": [
    "# So that looks really good! I was super stoked to see how close these values are to TABLE III in Hellwarth\n",
    "# However, the solutions all start on (7.20,6.50) so that top-left data point is cheating, whereas the \n",
    "# others have some disagreement / noise associated with them\n",
    "# I was wondering whether it might be a function of the optimiser, so thought I'd try them all\n",
    "\n",
    "initial=[7.1,6.5]\n",
    "# Main use of these bounds is stopping v or w going negative, at which you get a NaN error as you are evaluating log(-ve Real)\n",
    "lower=[1.0,1.0]\n",
    "upper=[10.0,10.0]\n",
    "\n",
    "for optimizer in [BFGS, LBFGS, ConjugateGradient] # Newton, GradientDescent, NelderMead - steps outside box & log(-ve)->NaN error\n",
    "    @printf(\"\\n\\t\\t##### NOW TRIALING: %s #####\\n\\n\",optimizer)\n",
    "\n",
    "    @printf(\"\\t\\t\")\n",
    "    for α in 1:5\n",
    "        @printf(\"α=%d\\t\\t\",α)\n",
    "    end\n",
    "    @printf(\"\\n\")\n",
    "\n",
    "    for β in 1:0.25:3.0\n",
    "        print(\"β: $β  \\t||\")\n",
    "        for α in 1:5\n",
    "            myf(x) = F(x[1],x[2],β,α)\n",
    "            res=optimize(DifferentiableFunction(myf), initial, lower, upper, Fminbox(); optimizer = optimizer, optimizer_o=Optim.Options(autodiff=true))\n",
    "            minimum=Optim.minimizer(res)\n",
    "            #show(Optim.converged(res)) # All came out as 'true'\n",
    "                \n",
    "            #print(solution,\"\\t\")\n",
    "            @printf(\"%.2f %.2f\\t\",minimum[1],minimum[2])\n",
    "        end\n",
    "        println()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So why the (slight) disagreement? I don't really know.\n",
    "# It may well be that Julia has a much better control of errors, \n",
    "# certainly the optimisation defaults seem to be at the Machine-precision end of the world, \n",
    "# and a lot of intermediates will be Float64 or larger.\n",
    "\n",
    "# The objective function seems quite flat in the vicinity of the optimum, so this would also explain some of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced mass: 0.17100885128857163\n",
      "Feynman Polaron Radius: 1.3542783798281395\n"
     ]
    }
   ],
   "source": [
    "# OK, now Ref 9; Schultz PR Volume 116, Number 3, Nov 1959\n",
    "const MassElectron = 9.10938188e-31;                          # kg\n",
    "v=7.15 \n",
    "w=6.51\n",
    "\n",
    "m=1.0 #MassElectron\n",
    "# Eqn (2.4)\n",
    "μ=m*(v^2-w^2)/v^2\n",
    "println(\"Reduced mass: $μ\")\n",
    "rf=(3/2*μ*v)^(1/2)\n",
    "println(\"Feynman Polaron Radius: $rf\")\n",
    "\n",
    "# Units?!? Bohr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 required packages:\n",
      " - ApproxFun                     0.5.0\n",
      " - BenchmarkTools                0.0.7\n",
      " - Combinatorics                 0.3.2\n",
      " - DataArrays                    0.3.12\n",
      " - DataFrames                    0.8.5\n",
      " - GR                            0.19.0\n",
      " - HDF5                          0.7.3\n",
      " - IJulia                        1.4.1\n",
      " - Images                        0.7.0\n",
      " - Lazy                          0.11.5\n",
      " - ODE                           0.3.0\n",
      " - Optim                         0.7.4\n",
      " - Plots                         0.10.3\n",
      " - PyPlot                        2.3.1              master\n",
      " - QuadGK                        0.1.1\n",
      " - SIUnits                       0.1.0\n",
      " - UnicodePlots                  0.2.2\n",
      "71 additional packages:\n",
      " - AxisArrays                    0.0.3\n",
      " - BandedMatrices                0.2.1\n",
      " - BinDeps                       0.4.5\n",
      " - Blosc                         0.1.7\n",
      " - Calculus                      0.2.0\n",
      " - CatIndices                    0.0.1\n",
      " - ColorTypes                    0.3.0\n",
      " - ColorVectorSpace              0.2.0\n",
      " - Colors                        0.7.0\n",
      " - Compat                        0.16.1\n",
      " - ComputationalResources        0.0.1\n",
      " - Conda                         0.5.1\n",
      " - CustomUnitRanges              0.0.3\n",
      " - DataStructures                0.5.2\n",
      " - DiffBase                      0.0.4\n",
      " - DiffEqBase                    0.10.0\n",
      " - DualNumbers                   0.2.3\n",
      " - FFTViews                      0.0.1\n",
      " - FastGaussQuadrature           0.1.0\n",
      " - FastTransforms                0.0.7\n",
      " - FileIO                        0.3.0\n",
      " - FixedPointNumbers             0.3.1\n",
      " - FixedSizeArrays               0.2.5\n",
      " - ForwardDiff                   0.3.4\n",
      " - GZip                          0.2.20\n",
      " - Graphics                      0.1.3\n",
      " - Hiccup                        0.1.1\n",
      " - Homebrew                      0.4.2\n",
      " - ImageAxes                     0.1.0\n",
      " - ImageCore                     0.1.1\n",
      " - ImageFiltering                0.1.1\n",
      " - ImageMetadata                 0.1.1\n",
      " - IndirectArrays                0.1.0\n",
      " - IntervalSets                  0.0.2\n",
      " - Iterators                     0.2.0\n",
      " - JLD                           0.6.9\n",
      " - JSON                          0.8.2\n",
      " - Juno                          0.2.5\n",
      " - LaTeXStrings                  0.2.0\n",
      " - LegacyStrings                 0.2.0\n",
      " - LineSearches                  0.1.5\n",
      " - MacroTools                    0.3.4\n",
      " - MappedArrays                  0.0.5\n",
      " - Measures                      0.0.3\n",
      " - Media                         0.2.5\n",
      " - NaNMath                       0.2.2\n",
      " - Nettle                        0.2.4\n",
      " - OffsetArrays                  0.2.12\n",
      " - Parameters                    0.6.0\n",
      " - PlotThemes                    0.1.0\n",
      " - PlotUtils                     0.3.0\n",
      " - Polynomials                   0.1.2\n",
      " - PositiveFactorizations        0.0.4\n",
      " - PyCall                        1.10.0             master\n",
      " - RangeArrays                   0.1.1\n",
      " - Ranges                        0.0.1\n",
      " - RecipesBase                   0.1.0\n",
      " - RecursiveArrayTools           0.2.0\n",
      " - Reexport                      0.0.3\n",
      " - SHA                           0.3.1\n",
      " - ShowItLikeYouBuildIt          0.0.1\n",
      " - Showoff                       0.0.7\n",
      " - SimpleTraits                  0.2.0\n",
      " - SortingAlgorithms             0.1.0\n",
      " - StaticArrays                  0.1.4\n",
      " - StatsBase                     0.13.0\n",
      " - TexExtensions                 0.0.3\n",
      " - TiledIteration                0.0.1\n",
      " - ToeplitzMatrices              0.1.1\n",
      " - URIParser                     0.1.8\n",
      " - ZMQ                           0.4.1\n"
     ]
    }
   ],
   "source": [
    "# P.S. Versions of packages used here:\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
